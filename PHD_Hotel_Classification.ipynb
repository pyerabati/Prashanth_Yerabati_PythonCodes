{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import random\n",
    "import gensim\n",
    "import nltk\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"E:\\Insofe\\PH.D\\PHD_ML\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('Train-1554810061973.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Reviewid</th>\n",
       "      <th>Hotelid</th>\n",
       "      <th>userid</th>\n",
       "      <th>Date</th>\n",
       "      <th>reviewtext</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Review_1</td>\n",
       "      <td>hotel_101</td>\n",
       "      <td>hotel_1608</td>\n",
       "      <td>Nov 16, 2007</td>\n",
       "      <td>Nice Marriot       View of my king bed room</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Review_2</td>\n",
       "      <td>hotel_101</td>\n",
       "      <td>hotel_6939</td>\n",
       "      <td>Oct 30, 2007</td>\n",
       "      <td>Good hotel, charges for internet access The Ma...</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Review_3</td>\n",
       "      <td>hotel_101</td>\n",
       "      <td>hotel_3976</td>\n",
       "      <td>Oct 12, 2007</td>\n",
       "      <td>Small but adequate rooms If you have an early ...</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Review_4</td>\n",
       "      <td>hotel_101</td>\n",
       "      <td>hotel_2851</td>\n",
       "      <td>Aug 31, 2007</td>\n",
       "      <td>Better than average, some noisy rooms I have s...</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Review_5</td>\n",
       "      <td>hotel_101</td>\n",
       "      <td>hotel_7897</td>\n",
       "      <td>Jul 18, 2007</td>\n",
       "      <td>Ordinary Although it is highly rated in these ...</td>\n",
       "      <td>bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Review_6</td>\n",
       "      <td>hotel_101</td>\n",
       "      <td>hotel_3297</td>\n",
       "      <td>Jul 13, 2007</td>\n",
       "      <td>Awesome for early AM flight Wow! what a supris...</td>\n",
       "      <td>excellent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Review_7</td>\n",
       "      <td>hotel_101</td>\n",
       "      <td>hotel_5463</td>\n",
       "      <td>Jul 4, 2007</td>\n",
       "      <td>Good Stay Spent two nights there in Jun. The h...</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Review_8</td>\n",
       "      <td>hotel_101</td>\n",
       "      <td>hotel_9766</td>\n",
       "      <td>Jun 14, 2007</td>\n",
       "      <td>Great Staff We stayed overnight the last week ...</td>\n",
       "      <td>excellent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Review_9</td>\n",
       "      <td>hotel_101</td>\n",
       "      <td>hotel_7042</td>\n",
       "      <td>Jun 13, 2007</td>\n",
       "      <td>fine choice for seatac The lobby is attractive...</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Review_10</td>\n",
       "      <td>hotel_101</td>\n",
       "      <td>hotel_9805</td>\n",
       "      <td>May 30, 2007</td>\n",
       "      <td>Great value, looking for a nice hotel. not exp...</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Review_11</td>\n",
       "      <td>hotel_101</td>\n",
       "      <td>hotel_3038</td>\n",
       "      <td>May 27, 2007</td>\n",
       "      <td>Very nice but expensive parking This hotel is ...</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Review_12</td>\n",
       "      <td>hotel_101</td>\n",
       "      <td>hotel_8402</td>\n",
       "      <td>Apr 28, 2007</td>\n",
       "      <td>Very Happy With My Stay This property has not ...</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Review_13</td>\n",
       "      <td>hotel_101</td>\n",
       "      <td>hotel_8906</td>\n",
       "      <td>Apr 20, 2007</td>\n",
       "      <td>Nickel and Dimed to death. The hotel is nice a...</td>\n",
       "      <td>bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Review_14</td>\n",
       "      <td>hotel_101</td>\n",
       "      <td>hotel_10390</td>\n",
       "      <td>Mar 13, 2007</td>\n",
       "      <td>Extraordinaily Positive Staff I stayed March 4...</td>\n",
       "      <td>excellent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Review_15</td>\n",
       "      <td>hotel_101</td>\n",
       "      <td>hotel_7842</td>\n",
       "      <td>Mar 3, 2007</td>\n",
       "      <td>Birthday party fun!! We stayed here overnite, ...</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Review_16</td>\n",
       "      <td>hotel_101</td>\n",
       "      <td>hotel_7474</td>\n",
       "      <td>Jan 16, 2007</td>\n",
       "      <td>Excellent stay! We stayed at the hotel for one...</td>\n",
       "      <td>excellent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Review_17</td>\n",
       "      <td>hotel_101</td>\n",
       "      <td>hotel_9746</td>\n",
       "      <td>Dec 12, 2006</td>\n",
       "      <td>Great business trip hotel The hotel is somewha...</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Review_18</td>\n",
       "      <td>hotel_101</td>\n",
       "      <td>hotel_5911</td>\n",
       "      <td>Nov 21, 2006</td>\n",
       "      <td>Sleep, Park and Fly We parked our SUV within 5...</td>\n",
       "      <td>bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Review_19</td>\n",
       "      <td>hotel_101</td>\n",
       "      <td>hotel_1202</td>\n",
       "      <td>Nov 14, 2006</td>\n",
       "      <td>Comfortable but not spacious After staying two...</td>\n",
       "      <td>excellent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Review_20</td>\n",
       "      <td>hotel_101</td>\n",
       "      <td>hotel_5764</td>\n",
       "      <td>Aug 26, 2006</td>\n",
       "      <td>Rooms Are Beautiful After Recent Renovation   ...</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Review_21</td>\n",
       "      <td>hotel_101</td>\n",
       "      <td>hotel_8038</td>\n",
       "      <td>Jul 20, 2006</td>\n",
       "      <td>Hit or miss Stayed here on 2 separate occasion...</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Review_22</td>\n",
       "      <td>hotel_101</td>\n",
       "      <td>hotel_6887</td>\n",
       "      <td>Jul 17, 2006</td>\n",
       "      <td>Great hotel July 2006 - We stayed at the Court...</td>\n",
       "      <td>excellent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Review_23</td>\n",
       "      <td>hotel_101</td>\n",
       "      <td>hotel_6283</td>\n",
       "      <td>Jun 12, 2006</td>\n",
       "      <td>Pretty impressed Stayed one night here after d...</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Review_24</td>\n",
       "      <td>hotel_101</td>\n",
       "      <td>hotel_9521</td>\n",
       "      <td>Aug 4, 2005</td>\n",
       "      <td>Interesting Marriott Property       Another vi...</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Review_25</td>\n",
       "      <td>hotel_101</td>\n",
       "      <td>hotel_8148</td>\n",
       "      <td>May 19, 2005</td>\n",
       "      <td>Kind of worn out!   showReview(3484581, 'full');</td>\n",
       "      <td>bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Review_26</td>\n",
       "      <td>hotel_101</td>\n",
       "      <td>hotel_7721</td>\n",
       "      <td>Mar 8, 2005</td>\n",
       "      <td>Below Average, old and tired   showReview(3258...</td>\n",
       "      <td>bad</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Reviewid    Hotelid       userid          Date  \\\n",
       "0    Review_1  hotel_101   hotel_1608  Nov 16, 2007   \n",
       "1    Review_2  hotel_101   hotel_6939  Oct 30, 2007   \n",
       "2    Review_3  hotel_101   hotel_3976  Oct 12, 2007   \n",
       "3    Review_4  hotel_101   hotel_2851  Aug 31, 2007   \n",
       "4    Review_5  hotel_101   hotel_7897  Jul 18, 2007   \n",
       "5    Review_6  hotel_101   hotel_3297  Jul 13, 2007   \n",
       "6    Review_7  hotel_101   hotel_5463   Jul 4, 2007   \n",
       "7    Review_8  hotel_101   hotel_9766  Jun 14, 2007   \n",
       "8    Review_9  hotel_101   hotel_7042  Jun 13, 2007   \n",
       "9   Review_10  hotel_101   hotel_9805  May 30, 2007   \n",
       "10  Review_11  hotel_101   hotel_3038  May 27, 2007   \n",
       "11  Review_12  hotel_101   hotel_8402  Apr 28, 2007   \n",
       "12  Review_13  hotel_101   hotel_8906  Apr 20, 2007   \n",
       "13  Review_14  hotel_101  hotel_10390  Mar 13, 2007   \n",
       "14  Review_15  hotel_101   hotel_7842   Mar 3, 2007   \n",
       "15  Review_16  hotel_101   hotel_7474  Jan 16, 2007   \n",
       "16  Review_17  hotel_101   hotel_9746  Dec 12, 2006   \n",
       "17  Review_18  hotel_101   hotel_5911  Nov 21, 2006   \n",
       "18  Review_19  hotel_101   hotel_1202  Nov 14, 2006   \n",
       "19  Review_20  hotel_101   hotel_5764  Aug 26, 2006   \n",
       "20  Review_21  hotel_101   hotel_8038  Jul 20, 2006   \n",
       "21  Review_22  hotel_101   hotel_6887  Jul 17, 2006   \n",
       "22  Review_23  hotel_101   hotel_6283  Jun 12, 2006   \n",
       "23  Review_24  hotel_101   hotel_9521   Aug 4, 2005   \n",
       "24  Review_25  hotel_101   hotel_8148  May 19, 2005   \n",
       "25  Review_26  hotel_101   hotel_7721   Mar 8, 2005   \n",
       "\n",
       "                                           reviewtext  Sentiment  \n",
       "0         Nice Marriot       View of my king bed room       good  \n",
       "1   Good hotel, charges for internet access The Ma...       good  \n",
       "2   Small but adequate rooms If you have an early ...       good  \n",
       "3   Better than average, some noisy rooms I have s...       good  \n",
       "4   Ordinary Although it is highly rated in these ...        bad  \n",
       "5   Awesome for early AM flight Wow! what a supris...  excellent  \n",
       "6   Good Stay Spent two nights there in Jun. The h...       good  \n",
       "7   Great Staff We stayed overnight the last week ...  excellent  \n",
       "8   fine choice for seatac The lobby is attractive...       good  \n",
       "9   Great value, looking for a nice hotel. not exp...       good  \n",
       "10  Very nice but expensive parking This hotel is ...       good  \n",
       "11  Very Happy With My Stay This property has not ...       good  \n",
       "12  Nickel and Dimed to death. The hotel is nice a...        bad  \n",
       "13  Extraordinaily Positive Staff I stayed March 4...  excellent  \n",
       "14  Birthday party fun!! We stayed here overnite, ...       good  \n",
       "15  Excellent stay! We stayed at the hotel for one...  excellent  \n",
       "16  Great business trip hotel The hotel is somewha...       good  \n",
       "17  Sleep, Park and Fly We parked our SUV within 5...        bad  \n",
       "18  Comfortable but not spacious After staying two...  excellent  \n",
       "19  Rooms Are Beautiful After Recent Renovation   ...       good  \n",
       "20  Hit or miss Stayed here on 2 separate occasion...       good  \n",
       "21  Great hotel July 2006 - We stayed at the Court...  excellent  \n",
       "22  Pretty impressed Stayed one night here after d...       good  \n",
       "23  Interesting Marriott Property       Another vi...       good  \n",
       "24   Kind of worn out!   showReview(3484581, 'full');        bad  \n",
       "25  Below Average, old and tired   showReview(3258...        bad  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.loc[train.Hotelid == 'hotel_101']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.Sentiment[train.Sentiment == 'bad'] = 0\n",
    "train.Sentiment[train.Sentiment == 'good'] = 1\n",
    "train.Sentiment[train.Sentiment == 'excellent'] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average count of reviews per hotel in train is 63.\n"
     ]
    }
   ],
   "source": [
    "print('Average count of reviews per hotel in train is {0:.0f}.'.format(train.groupby('Hotelid')['reviewtext'].count().mean()))\n",
    "#print('Average count of phrases per sentence in test is {0:.0f}.'.format(test.groupby('Hotelid')['reviewtext'].count().mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of hotels in train: 6287. Number of reviews in train: 100.\n"
     ]
    }
   ],
   "source": [
    "print('Number of hotels in train: {}. Number of reviews in train: {}.'.format(train.shape[0], len(train.Hotelid.unique())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average word length of reviews in train is 168.\n"
     ]
    }
   ],
   "source": [
    "print('Average word length of reviews in train is {0:.0f}.'.format(np.mean(train['reviewtext'].apply(lambda x: len(x.split(\" \"))))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('Test-1555730055539.csv')\n",
    "#sub = pd.read_csv('../input/movie-review-sentiment-analysis-kernels-only/sampleSubmission.csv', sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Reviewid</th>\n",
       "      <th>Hotelid</th>\n",
       "      <th>userid</th>\n",
       "      <th>Date</th>\n",
       "      <th>reviewtext</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Review_11001</td>\n",
       "      <td>hotel_101</td>\n",
       "      <td>hotel_2225</td>\n",
       "      <td>Dec 13, 2008</td>\n",
       "      <td>Just An Average stay This was just an average ...</td>\n",
       "      <td>-999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Review_11002</td>\n",
       "      <td>hotel_101</td>\n",
       "      <td>hotel_5079</td>\n",
       "      <td>Dec 2, 2008</td>\n",
       "      <td>go elsewhere The place is hugely overpriced an...</td>\n",
       "      <td>-999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Review_11003</td>\n",
       "      <td>hotel_101</td>\n",
       "      <td>hotel_8440</td>\n",
       "      <td>Nov 18, 2008</td>\n",
       "      <td>I Won't Go Back I stayed at the hotel 11/14/08...</td>\n",
       "      <td>-999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Review_11004</td>\n",
       "      <td>hotel_101</td>\n",
       "      <td>hotel_4592</td>\n",
       "      <td>Oct 19, 2008</td>\n",
       "      <td>Good weekend stay My wife and I stay here quit...</td>\n",
       "      <td>-999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Review_11005</td>\n",
       "      <td>hotel_101</td>\n",
       "      <td>hotel_5901</td>\n",
       "      <td>Oct 13, 2008</td>\n",
       "      <td>Great airport stay Lovely indoor pool area, lo...</td>\n",
       "      <td>-999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Reviewid    Hotelid      userid          Date  \\\n",
       "0  Review_11001  hotel_101  hotel_2225  Dec 13, 2008   \n",
       "1  Review_11002  hotel_101  hotel_5079   Dec 2, 2008   \n",
       "2  Review_11003  hotel_101  hotel_8440  Nov 18, 2008   \n",
       "3  Review_11004  hotel_101  hotel_4592  Oct 19, 2008   \n",
       "4  Review_11005  hotel_101  hotel_5901  Oct 13, 2008   \n",
       "\n",
       "                                          reviewtext  Sentiment  \n",
       "0  Just An Average stay This was just an average ...       -999  \n",
       "1  go elsewhere The place is hugely overpriced an...       -999  \n",
       "2  I Won't Go Back I stayed at the hotel 11/14/08...       -999  \n",
       "3  Good weekend stay My wife and I stay here quit...       -999  \n",
       "4  Great airport stay Lovely indoor pool area, lo...       -999  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Adding Sentiment column to test datset and joing train and test for preprocessing\n",
    "\n",
    "test['Sentiment']=-999\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9755, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Reviewid</th>\n",
       "      <th>Hotelid</th>\n",
       "      <th>userid</th>\n",
       "      <th>Date</th>\n",
       "      <th>reviewtext</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9750</th>\n",
       "      <td>Review_14464</td>\n",
       "      <td>hotel_200</td>\n",
       "      <td>hotel_4764</td>\n",
       "      <td>Aug 18, 2008</td>\n",
       "      <td>Un hotel encantador, muy recomendable   showRe...</td>\n",
       "      <td>-999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9751</th>\n",
       "      <td>Review_14465</td>\n",
       "      <td>hotel_200</td>\n",
       "      <td>hotel_6698</td>\n",
       "      <td>Apr 20, 2008</td>\n",
       "      <td>Buon albergo   showReview(15155815, 'full');</td>\n",
       "      <td>-999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9752</th>\n",
       "      <td>Review_14466</td>\n",
       "      <td>hotel_200</td>\n",
       "      <td>hotel_6390</td>\n",
       "      <td>Apr 12, 2008</td>\n",
       "      <td>Un hotel eccezionale   showReview(14980612, 'f...</td>\n",
       "      <td>-999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9753</th>\n",
       "      <td>Review_14467</td>\n",
       "      <td>hotel_200</td>\n",
       "      <td>hotel_7902</td>\n",
       "      <td>Mar 28, 2008</td>\n",
       "      <td>Ottimo   showReview(14599783, 'full');</td>\n",
       "      <td>-999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9754</th>\n",
       "      <td>Review_14468</td>\n",
       "      <td>hotel_200</td>\n",
       "      <td>hotel_10561</td>\n",
       "      <td>Mar 22, 2008</td>\n",
       "      <td>Un relax en el ritmo trepidante de New York   ...</td>\n",
       "      <td>-999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Reviewid    Hotelid       userid          Date  \\\n",
       "9750  Review_14464  hotel_200   hotel_4764  Aug 18, 2008   \n",
       "9751  Review_14465  hotel_200   hotel_6698  Apr 20, 2008   \n",
       "9752  Review_14466  hotel_200   hotel_6390  Apr 12, 2008   \n",
       "9753  Review_14467  hotel_200   hotel_7902  Mar 28, 2008   \n",
       "9754  Review_14468  hotel_200  hotel_10561  Mar 22, 2008   \n",
       "\n",
       "                                             reviewtext Sentiment  \n",
       "9750  Un hotel encantador, muy recomendable   showRe...      -999  \n",
       "9751       Buon albergo   showReview(15155815, 'full');      -999  \n",
       "9752  Un hotel eccezionale   showReview(14980612, 'f...      -999  \n",
       "9753             Ottimo   showReview(14599783, 'full');      -999  \n",
       "9754  Un relax en el ritmo trepidante de New York   ...      -999  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.concat([train,test],ignore_index=True)\n",
    "print(df.shape)\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del train,test\n",
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cleaning review\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import FreqDist\n",
    "from nltk.stem import SnowballStemmer,WordNetLemmatizer\n",
    "stemmer=SnowballStemmer('english')\n",
    "lemma=WordNetLemmatizer()\n",
    "from string import punctuation\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_review(review_col):\n",
    "    review_corpus=[]\n",
    "    for i in range(0,len(review_col)):\n",
    "        review=str(review_col[i])\n",
    "        review=re.sub('[^a-zA-Z]',' ',review)\n",
    "        review=[stemmer.stem(w) for w in word_tokenize(str(review).lower())]\n",
    "        review=[lemma.lemmatize(w) for w in word_tokenize(str(review).lower())]\n",
    "        review=' '.join(review)\n",
    "        review_corpus.append(review)\n",
    "    return review_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\prash\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Reviewid</th>\n",
       "      <th>Hotelid</th>\n",
       "      <th>userid</th>\n",
       "      <th>Date</th>\n",
       "      <th>reviewtext</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>clean_review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Review_1</td>\n",
       "      <td>hotel_101</td>\n",
       "      <td>hotel_1608</td>\n",
       "      <td>Nov 16, 2007</td>\n",
       "      <td>Nice Marriot       View of my king bed room</td>\n",
       "      <td>1</td>\n",
       "      <td>[ 'nice ' , 'marriot ' , 'view ' , 'of ' , 'my...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Review_2</td>\n",
       "      <td>hotel_101</td>\n",
       "      <td>hotel_6939</td>\n",
       "      <td>Oct 30, 2007</td>\n",
       "      <td>Good hotel, charges for internet access The Ma...</td>\n",
       "      <td>1</td>\n",
       "      <td>[ 'good ' , 'hotel ' , 'charg ' , 'for ' , 'in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Review_3</td>\n",
       "      <td>hotel_101</td>\n",
       "      <td>hotel_3976</td>\n",
       "      <td>Oct 12, 2007</td>\n",
       "      <td>Small but adequate rooms If you have an early ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[ 'small ' , 'but ' , 'adequ ' , 'room ' , 'if...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Review_4</td>\n",
       "      <td>hotel_101</td>\n",
       "      <td>hotel_2851</td>\n",
       "      <td>Aug 31, 2007</td>\n",
       "      <td>Better than average, some noisy rooms I have s...</td>\n",
       "      <td>1</td>\n",
       "      <td>[ 'better ' , 'than ' , 'averag ' , 'some ' , ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Review_5</td>\n",
       "      <td>hotel_101</td>\n",
       "      <td>hotel_7897</td>\n",
       "      <td>Jul 18, 2007</td>\n",
       "      <td>Ordinary Although it is highly rated in these ...</td>\n",
       "      <td>0</td>\n",
       "      <td>[ 'ordinari ' , 'although ' , 'it ' , 'is ' , ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Reviewid    Hotelid      userid          Date  \\\n",
       "0  Review_1  hotel_101  hotel_1608  Nov 16, 2007   \n",
       "1  Review_2  hotel_101  hotel_6939  Oct 30, 2007   \n",
       "2  Review_3  hotel_101  hotel_3976  Oct 12, 2007   \n",
       "3  Review_4  hotel_101  hotel_2851  Aug 31, 2007   \n",
       "4  Review_5  hotel_101  hotel_7897  Jul 18, 2007   \n",
       "\n",
       "                                          reviewtext Sentiment  \\\n",
       "0        Nice Marriot       View of my king bed room         1   \n",
       "1  Good hotel, charges for internet access The Ma...         1   \n",
       "2  Small but adequate rooms If you have an early ...         1   \n",
       "3  Better than average, some noisy rooms I have s...         1   \n",
       "4  Ordinary Although it is highly rated in these ...         0   \n",
       "\n",
       "                                        clean_review  \n",
       "0  [ 'nice ' , 'marriot ' , 'view ' , 'of ' , 'my...  \n",
       "1  [ 'good ' , 'hotel ' , 'charg ' , 'for ' , 'in...  \n",
       "2  [ 'small ' , 'but ' , 'adequ ' , 'room ' , 'if...  \n",
       "3  [ 'better ' , 'than ' , 'averag ' , 'some ' , ...  \n",
       "4  [ 'ordinari ' , 'although ' , 'it ' , 'is ' , ...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "df['clean_review']=clean_review(df.reviewtext.values)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prash\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:3694: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  errors=errors)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3468, 6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prash\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#seperating train and test dataset\n",
    "df_train=df[df.Sentiment!=-999]\n",
    "df_train.shape\n",
    "df_test=df[df.Sentiment==-999]\n",
    "df_test.drop('Sentiment',axis=1,inplace=True)\n",
    "print(df_test.shape)\n",
    "df_test.head()\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6287,) (6287,) (6287, 3)\n"
     ]
    }
   ],
   "source": [
    "#Splitting Train dataset into train and 20% validation se\n",
    "train_text=df_train.clean_review.values\n",
    "test_text=df_test.clean_review.values\n",
    "target=df_train.Sentiment.values\n",
    "y=to_categorical(target)\n",
    "print(train_text.shape,target.shape,y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5029,) (5029, 3)\n",
      "(1258,) (1258, 3)\n"
     ]
    }
   ],
   "source": [
    "X_train_text,X_val_text,y_train,y_val=train_test_split(train_text,y,test_size=0.2,stratify=y,random_state=123)\n",
    "print(X_train_text.shape,y_train.shape)\n",
    "print(X_val_text.shape,y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12893"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Finding number of unique words in train set¶\n",
    "\n",
    "all_words=' '.join(X_train_text)\n",
    "all_words=word_tokenize(all_words)\n",
    "dist=FreqDist(all_words)\n",
    "num_unique_word=len(dist)\n",
    "num_unique_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4282"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Finding max length of a review in train se\n",
    "r_len=[]\n",
    "for text in X_train_text:\n",
    "    word=word_tokenize(text)\n",
    "    l=len(word)\n",
    "    r_len.append(l)\n",
    "    \n",
    "MAX_REVIEW_LEN=np.max(r_len)\n",
    "MAX_REVIEW_LEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Building Keras LSTM model¶\n",
    "#max_features = num_unique_word\n",
    "max_features = 10000\n",
    "#max_words = MAX_REVIEW_LEN\n",
    "max_words = 500\n",
    "batch_size = 64\n",
    "epochs = 3\n",
    "num_classes=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tokenize Text\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "tokenizer = Tokenizer(num_words=max_features)\n",
    "tokenizer.fit_on_texts(list(X_train_text))\n",
    "X_train = tokenizer.texts_to_sequences(X_train_text)\n",
    "X_val = tokenizer.texts_to_sequences(X_val_text)\n",
    "X_test = tokenizer.texts_to_sequences(test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5029, 500) (1258, 500) (3468, 500)\n"
     ]
    }
   ],
   "source": [
    "#sequence padding\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing import sequence\n",
    "X_train = sequence.pad_sequences(X_train, maxlen=max_words)\n",
    "X_val = sequence.pad_sequences(X_val, maxlen=max_words)\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=max_words)\n",
    "print(X_train.shape,X_val.shape,X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_40 (Embedding)     (None, None, 200)         2578600   \n",
      "_________________________________________________________________\n",
      "lstm_22 (LSTM)               (None, None, 64)          67840     \n",
      "_________________________________________________________________\n",
      "lstm_23 (LSTM)               (None, 32)                12416     \n",
      "_________________________________________________________________\n",
      "dense_53 (Dense)             (None, 3)                 99        \n",
      "=================================================================\n",
      "Total params: 2,658,955\n",
      "Trainable params: 2,658,955\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# LSTM Model\n",
    "from keras.layers import Input, Dense, Dropout, Embedding, LSTM, Flatten,Activation,BatchNormalization,Conv1D,Conv2D,MaxPooling2D\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adam\n",
    "model1=Sequential()\n",
    "model1.add(Embedding(max_features,200,mask_zero=True))\n",
    "model1.add(LSTM(64,dropout=0.2, recurrent_dropout=0.2,return_sequences=True))\n",
    "model1.add(LSTM(32,dropout=0.2, recurrent_dropout=0.3,return_sequences=False))\n",
    "model1.add(Dense(num_classes,activation='softmax'))\n",
    "model1.compile(loss='categorical_crossentropy',optimizer=Adam(lr=0.001),metrics=['accuracy'])\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5029 samples, validate on 1258 samples\n",
      "Epoch 1/3\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "history1=model1.fit(X_train, y_train, validation_data=(X_val, y_val),epochs=epochs, batch_size=batch_size, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred1=model1.predict_classes(X_test,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.read_csv('sampleSubmission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.Sentiment=y_pred1\n",
    "sub.Sentiment[sub.Sentiment == 0] = 'bad'\n",
    "sub.Sentiment[sub.Sentiment == 1] = 'good'\n",
    "sub.Sentiment[sub.Sentiment == 2] = 'excellent'\n",
    "sub.to_csv('sub1.csv',index=False)\n",
    "sub.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_9 (Embedding)      (None, 500, 100)          1000000   \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 500, 100)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_9 (Conv1D)            (None, 500, 64)           19264     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_5 (Glob (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 3)                 387       \n",
      "=================================================================\n",
      "Total params: 1,027,971\n",
      "Trainable params: 1,027,971\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "kernel_size = 3\n",
    "filters = 64\n",
    "pool_size = 3\n",
    "gru_node = 256\n",
    "\n",
    "from keras import regularizers\n",
    "from keras.layers import Input, Dense, Dropout, Embedding, LSTM, Flatten,Activation,BatchNormalization,Conv1D,Conv2D,GlobalMaxPooling1D,MaxPooling2D\n",
    "from keras.models import Sequential\n",
    "\n",
    "model2= Sequential()\n",
    "model2.add(Embedding(max_features,100,input_length=max_words))\n",
    "model2.add(Dropout(0.15))\n",
    "\n",
    "model2.add(Conv1D(64,kernel_size=3,padding='same',activation='relu',strides=1))\n",
    "model2.add(GlobalMaxPooling1D())\n",
    "\n",
    "model2.add(Dense(128,activation='relu'))\n",
    "model2.add(Dropout(0.25))\n",
    "\n",
    "model2.add(Dense(num_classes,activation='softmax'))\n",
    "\n",
    "\n",
    "model2.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5029 samples, validate on 1258 samples\n",
      "Epoch 1/6\n",
      "5029/5029 [==============================] - 11s 2ms/step - loss: 1.0040 - acc: 0.5065 - val_loss: 0.9551 - val_acc: 0.5111\n",
      "Epoch 2/6\n",
      "5029/5029 [==============================] - 12s 2ms/step - loss: 0.8578 - acc: 0.5776 - val_loss: 0.7708 - val_acc: 0.6288\n",
      "Epoch 3/6\n",
      "5029/5029 [==============================] - 14s 3ms/step - loss: 0.6813 - acc: 0.6791 - val_loss: 0.6891 - val_acc: 0.6614\n",
      "Epoch 4/6\n",
      "5029/5029 [==============================] - 13s 3ms/step - loss: 0.5407 - acc: 0.7658 - val_loss: 0.6576 - val_acc: 0.6828\n",
      "Epoch 5/6\n",
      "5029/5029 [==============================] - 13s 3ms/step - loss: 0.4230 - acc: 0.8314 - val_loss: 0.7034 - val_acc: 0.6741\n",
      "Epoch 6/6\n",
      "5029/5029 [==============================] - 13s 3ms/step - loss: 0.3108 - acc: 0.8839 - val_loss: 0.7486 - val_acc: 0.6749\n",
      "Wall time: 1min 15s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "history2=model2.fit(X_train, y_train, validation_data=(X_val, y_val),epochs=6, batch_size=batch_size, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "5029/5029 [==============================] - 11s 2ms/step - loss: 1.0157 - acc: 0.4985\n",
      "Epoch 2/8\n",
      "  64/5029 [..............................] - ETA: 10s - loss: 1.0318 - acc: 0.4844"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prash\\Anaconda3\\lib\\site-packages\\keras\\callbacks.py:434: RuntimeWarning: Can save best model only with val_acc available, skipping.\n",
      "  'skipping.' % (self.monitor), RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5029/5029 [==============================] - 11s 2ms/step - loss: 0.9069 - acc: 0.5484\n",
      "Epoch 3/8\n",
      "5029/5029 [==============================] - 12s 2ms/step - loss: 0.7222 - acc: 0.6480\n",
      "Epoch 4/8\n",
      "5029/5029 [==============================] - 12s 2ms/step - loss: 0.6108 - acc: 0.7168\n",
      "Epoch 5/8\n",
      "5029/5029 [==============================] - 12s 2ms/step - loss: 0.5167 - acc: 0.7773\n",
      "Epoch 6/8\n",
      "5029/5029 [==============================] - 12s 2ms/step - loss: 0.4272 - acc: 0.8276\n",
      "Epoch 7/8\n",
      "5029/5029 [==============================] - 12s 2ms/step - loss: 0.3379 - acc: 0.8686\n",
      "Epoch 8/8\n",
      "5029/5029 [==============================] - 12s 2ms/step - loss: 0.2544 - acc: 0.9077\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "filepath=\"weights-simple.hdf5\"\n",
    "checkpointer = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "history = model2.fit([X_train], batch_size=64, y=y_train, verbose=1, \n",
    "          shuffle=True, epochs=8, callbacks=[checkpointer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3468/3468 [==============================] - 5s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred2=model2.predict_classes(X_test, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prash\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Reviewid</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Review_11001</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Review_11002</td>\n",
       "      <td>bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Review_11003</td>\n",
       "      <td>bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Review_11004</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Review_11005</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Reviewid Sentiment\n",
       "0  Review_11001      good\n",
       "1  Review_11002       bad\n",
       "2  Review_11003       bad\n",
       "3  Review_11004      good\n",
       "4  Review_11005      good"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub.Sentiment=y_pred2\n",
    "sub.Sentiment[sub.Sentiment == 0] = 'bad'\n",
    "sub.Sentiment[sub.Sentiment == 1] = 'good'\n",
    "sub.Sentiment[sub.Sentiment == 2] = 'excellent'\n",
    "sub.to_csv('sub2_next_0428.csv',index=False)\n",
    "sub.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN +GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, 1427, 100)         1652000   \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 1427, 64)          19264     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 713, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 713, 64)           0         \n",
      "_________________________________________________________________\n",
      "gru_1 (GRU)                  (None, 713, 128)          74112     \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 713, 128)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 91264)             0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 128)               11681920  \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 3)                 387       \n",
      "=================================================================\n",
      "Total params: 13,427,683\n",
      "Trainable params: 13,427,683\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from keras.layers import GRU,Input, Dense, Dropout, Embedding, LSTM, Flatten,Activation,BatchNormalization,Conv1D,Conv2D,MaxPooling1D,GlobalMaxPooling1D,MaxPooling2D\n",
    "\n",
    "model3= Sequential()\n",
    "model3.add(Embedding(max_features,100,input_length=max_words))\n",
    "model3.add(Conv1D(64,kernel_size=3,padding='same',activation='relu'))\n",
    "model3.add(MaxPooling1D(pool_size=2))\n",
    "model3.add(Dropout(0.25))\n",
    "model3.add(GRU(128,return_sequences=True))\n",
    "model3.add(Dropout(0.3))\n",
    "model3.add(Flatten())\n",
    "model3.add(Dense(128,activation='relu'))\n",
    "model3.add(Dropout(0.5))\n",
    "model3.add(Dense(3,activation='softmax'))\n",
    "model3.compile(loss='categorical_crossentropy',optimizer=Adam(lr=0.001),metrics=['accuracy'])\n",
    "model3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5029 samples, validate on 1258 samples\n",
      "Epoch 1/10\n",
      "5029/5029 [==============================] - 152s 30ms/step - loss: 1.0494 - acc: 0.4727 - val_loss: 0.9923 - val_acc: 0.5111\n",
      "Epoch 2/10\n",
      "5029/5029 [==============================] - 167s 33ms/step - loss: 0.8895 - acc: 0.5357 - val_loss: 0.7185 - val_acc: 0.6463\n",
      "Epoch 3/10\n",
      "5029/5029 [==============================] - 174s 35ms/step - loss: 0.6201 - acc: 0.7041 - val_loss: 0.6730 - val_acc: 0.6709\n",
      "Epoch 4/10\n",
      "5029/5029 [==============================] - 175s 35ms/step - loss: 0.3937 - acc: 0.8282 - val_loss: 0.7638 - val_acc: 0.6852\n",
      "Epoch 5/10\n",
      "5029/5029 [==============================] - 184s 37ms/step - loss: 0.2513 - acc: 0.8954 - val_loss: 0.9295 - val_acc: 0.6900\n",
      "Epoch 6/10\n",
      "1408/5029 [=======>......................] - ETA: 2:09 - loss: 0.1789 - acc: 0.9283"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1039\u001b[1;33m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1040\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2713\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2714\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2715\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2716\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2717\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2674\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2675\u001b[1;33m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2676\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[0;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1439\u001b[1;33m               run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1440\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "history3=model3.fit(X_train, y_train, validation_data=(X_val, y_val),epochs=10, batch_size=batch_size, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7504/7504 [==============================] - 49s 7ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred3=model3.predict_classes(X_test, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prash\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userid</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hotel_2225</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hotel_5079</td>\n",
       "      <td>bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hotel_8440</td>\n",
       "      <td>bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hotel_4592</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hotel_5901</td>\n",
       "      <td>excellent</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       userid  Sentiment\n",
       "0  hotel_2225       good\n",
       "1  hotel_5079        bad\n",
       "2  hotel_8440        bad\n",
       "3  hotel_4592       good\n",
       "4  hotel_5901  excellent"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub.Sentiment=y_pred3\n",
    "sub.Sentiment[sub.Sentiment == 0] = 'bad'\n",
    "sub.Sentiment[sub.Sentiment == 1] = 'good'\n",
    "sub.Sentiment[sub.Sentiment == 2] = 'excellent'\n",
    "sub.to_csv('sub3.csv',index=False)\n",
    "sub.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Bidirectional GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_5 (Embedding)      (None, 1427, 100)         1652000   \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_1 (Spatial (None, 1427, 100)         0         \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 256)               175872    \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 3)                 771       \n",
      "=================================================================\n",
      "Total params: 1,828,643\n",
      "Trainable params: 1,828,643\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Embedding, Reshape, merge, LSTM, Bidirectional, SpatialDropout1D\n",
    "model4 = Sequential()\n",
    "\n",
    "model4.add(Embedding(max_features, 100, input_length=max_words))\n",
    "model4.add(SpatialDropout1D(0.25))\n",
    "model4.add(Bidirectional(GRU(128)))\n",
    "model4.add(Dropout(0.5))\n",
    "\n",
    "model4.add(Dense(3, activation='softmax'))\n",
    "model4.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model4.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5029 samples, validate on 1258 samples\n",
      "Epoch 1/3\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1039\u001b[1;33m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1040\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2713\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2714\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2715\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2716\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2717\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2674\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2675\u001b[1;33m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2676\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[0;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1439\u001b[1;33m               run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1440\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "history4=model4.fit(X_train, y_train, validation_data=(X_val, y_val),epochs=epochs, batch_size=batch_size, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7504/7504 [==============================] - 94s 13ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred4=model4.predict_classes(X_test, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prash\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userid</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hotel_2225</td>\n",
       "      <td>bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hotel_5079</td>\n",
       "      <td>bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hotel_8440</td>\n",
       "      <td>bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hotel_4592</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hotel_5901</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       userid Sentiment\n",
       "0  hotel_2225       bad\n",
       "1  hotel_5079       bad\n",
       "2  hotel_8440       bad\n",
       "3  hotel_4592      good\n",
       "4  hotel_5901      good"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub.Sentiment=y_pred4\n",
    "sub.Sentiment[sub.Sentiment == 0] = 'bad'\n",
    "sub.Sentiment[sub.Sentiment == 1] = 'good'\n",
    "sub.Sentiment[sub.Sentiment == 2] = 'excellent'\n",
    "sub.to_csv('sub4.csv',index=False)\n",
    "sub.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Glove word embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_coefs(word, *arr):\n",
    "    return word, np.asarray(arr, dtype='float32')\n",
    "    \n",
    "def get_embed_mat(EMBEDDING_FILE, max_features,embed_dim):\n",
    "    # word vectors\n",
    "    embeddings_index = dict(get_coefs(*o.rstrip().rsplit(' ')) for o in open(EMBEDDING_FILE, encoding='utf8'))\n",
    "    print('Found %s word vectors.' % len(embeddings_index))\n",
    "\n",
    "    # embedding matrix\n",
    "    word_index = tokenizer.word_index\n",
    "    num_words = min(max_features, len(word_index) + 1)\n",
    "    all_embs = np.stack(embeddings_index.values()) #for random init\n",
    "    embedding_matrix = np.random.normal(all_embs.mean(), all_embs.std(), \n",
    "                                        (num_words, embed_dim))\n",
    "    for word, i in word_index.items():\n",
    "        if i >= max_features:\n",
    "            continue\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[i] = embedding_vector\n",
    "    max_features = embedding_matrix.shape[0]\n",
    "    \n",
    "    return embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400000 word vectors.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prash\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:12: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  if sys.path[0] == '':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16520, 100)\n"
     ]
    }
   ],
   "source": [
    "# embedding matrix\n",
    "EMBEDDING_FILE = 'glove.6B.100d.txt'\n",
    "embed_dim = 100 #word vector dim\n",
    "embedding_matrix = get_embed_mat(EMBEDDING_FILE,max_features,embed_dim)\n",
    "print(embedding_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_6 (Embedding)      (None, 1427, 100)         1652000   \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_2 (Spatial (None, 1427, 100)         0         \n",
      "_________________________________________________________________\n",
      "bidirectional_2 (Bidirection (None, 1427, 256)         175872    \n",
      "_________________________________________________________________\n",
      "bidirectional_3 (Bidirection (None, 128)               123264    \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 3)                 387       \n",
      "=================================================================\n",
      "Total params: 1,951,523\n",
      "Trainable params: 1,951,523\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model5 = Sequential()\n",
    "model5.add(Embedding(max_features, embed_dim, input_length=X_train.shape[1],weights=[embedding_matrix],trainable=True))\n",
    "model5.add(SpatialDropout1D(0.25))\n",
    "model5.add(Bidirectional(GRU(128,return_sequences=True)))\n",
    "model5.add(Bidirectional(GRU(64,return_sequences=False)))\n",
    "model5.add(Dropout(0.5))\n",
    "model5.add(Dense(num_classes, activation='softmax'))\n",
    "model5.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model5.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5029 samples, validate on 1258 samples\n",
      "Epoch 1/4\n",
      "5029/5029 [==============================] - 6176s 1s/step - loss: 1.0582 - acc: 0.4754 - val_loss: 1.0098 - val_acc: 0.5087\n",
      "Epoch 2/4\n",
      "5029/5029 [==============================] - 7078s 1s/step - loss: 1.0179 - acc: 0.4925 - val_loss: 0.9813 - val_acc: 0.5286\n",
      "Epoch 3/4\n",
      "5029/5029 [==============================] - 14129s 3s/step - loss: 0.9876 - acc: 0.5126 - val_loss: 0.9457 - val_acc: 0.5382\n",
      "Epoch 4/4\n",
      "5029/5029 [==============================] - 10773s 2s/step - loss: 0.8996 - acc: 0.5546 - val_loss: 0.7819 - val_acc: 0.6161\n",
      "Wall time: 10h 35min 57s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "history5=model5.fit(X_train, y_train, validation_data=(X_val, y_val),epochs=4, batch_size=batch_size, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7504/7504 [==============================] - 397s 53ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred5=model5.predict_classes(X_test, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_pred5' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-70-ea7c93639666>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msub\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSentiment\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my_pred5\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0msub\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSentiment\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0msub\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSentiment\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'bad'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0msub\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSentiment\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0msub\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSentiment\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'good'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0msub\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSentiment\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0msub\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSentiment\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'excellent'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0msub\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'sub5.csv'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'y_pred5' is not defined"
     ]
    }
   ],
   "source": [
    "sub.Sentiment=y_pred5\n",
    "sub.Sentiment[sub.Sentiment == 0] = 'bad'\n",
    "sub.Sentiment[sub.Sentiment == 1] = 'good'\n",
    "sub.Sentiment[sub.Sentiment == 2] = 'excellent'\n",
    "sub.to_csv('sub5.csv',index=False)\n",
    "sub.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# combine all output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_all=pd.DataFrame({'model1':y_pred1,'model2':y_pred2,'model3':y_pred3,'model4':y_pred4,'model5':y_pred5})\n",
    "pred_mode=sub_all.agg('mode',axis=1)[0].values\n",
    "sub_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_mode=[int(i) for i in pred_mode]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.Sentiment=pred_mode\n",
    "sub.to_csv('sub_mode.csv',index=False)\n",
    "sub.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
