{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pylab import rcParams\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "RANDOM_SEED =7124\n",
    "LABELS = [\"Normal\", \"Fraud\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 30)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading the data and lookng at the structure of the data. This data has 30 attributes and 1 lakh records\n",
    "data = pd.read_csv(\"Fraud_data_amtstd.csv\")\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.836500</td>\n",
       "      <td>-0.545419</td>\n",
       "      <td>-0.462979</td>\n",
       "      <td>0.537174</td>\n",
       "      <td>-0.426143</td>\n",
       "      <td>-0.100606</td>\n",
       "      <td>-0.584764</td>\n",
       "      <td>-0.103956</td>\n",
       "      <td>2.268429</td>\n",
       "      <td>-0.365185</td>\n",
       "      <td>...</td>\n",
       "      <td>0.085111</td>\n",
       "      <td>0.410736</td>\n",
       "      <td>0.137625</td>\n",
       "      <td>0.602906</td>\n",
       "      <td>-0.350260</td>\n",
       "      <td>0.464407</td>\n",
       "      <td>-0.070917</td>\n",
       "      <td>-0.030486</td>\n",
       "      <td>0.049882</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-4.289880</td>\n",
       "      <td>-2.576061</td>\n",
       "      <td>-0.092256</td>\n",
       "      <td>1.976405</td>\n",
       "      <td>2.810033</td>\n",
       "      <td>-2.669128</td>\n",
       "      <td>-0.981883</td>\n",
       "      <td>-0.470310</td>\n",
       "      <td>-0.025692</td>\n",
       "      <td>0.099528</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.473240</td>\n",
       "      <td>-0.307295</td>\n",
       "      <td>-2.789549</td>\n",
       "      <td>0.578976</td>\n",
       "      <td>-0.837979</td>\n",
       "      <td>0.372843</td>\n",
       "      <td>0.353451</td>\n",
       "      <td>-1.662202</td>\n",
       "      <td>-0.347171</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.131318</td>\n",
       "      <td>0.139818</td>\n",
       "      <td>0.586921</td>\n",
       "      <td>1.069291</td>\n",
       "      <td>-0.334908</td>\n",
       "      <td>-0.204938</td>\n",
       "      <td>-0.135526</td>\n",
       "      <td>0.043821</td>\n",
       "      <td>-0.121117</td>\n",
       "      <td>0.182139</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.028126</td>\n",
       "      <td>-0.167062</td>\n",
       "      <td>-0.048054</td>\n",
       "      <td>-0.009912</td>\n",
       "      <td>0.417694</td>\n",
       "      <td>-0.479793</td>\n",
       "      <td>0.024360</td>\n",
       "      <td>0.023878</td>\n",
       "      <td>-0.208963</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.866956</td>\n",
       "      <td>1.373947</td>\n",
       "      <td>1.948343</td>\n",
       "      <td>2.686750</td>\n",
       "      <td>-0.366790</td>\n",
       "      <td>0.568632</td>\n",
       "      <td>-0.278349</td>\n",
       "      <td>0.739536</td>\n",
       "      <td>-1.655955</td>\n",
       "      <td>0.708396</td>\n",
       "      <td>...</td>\n",
       "      <td>0.022719</td>\n",
       "      <td>-0.070619</td>\n",
       "      <td>-0.080307</td>\n",
       "      <td>0.000816</td>\n",
       "      <td>0.092167</td>\n",
       "      <td>0.159131</td>\n",
       "      <td>0.157940</td>\n",
       "      <td>-0.014370</td>\n",
       "      <td>-0.253595</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.842670</td>\n",
       "      <td>1.401843</td>\n",
       "      <td>0.927235</td>\n",
       "      <td>1.070402</td>\n",
       "      <td>0.843883</td>\n",
       "      <td>0.467333</td>\n",
       "      <td>0.366716</td>\n",
       "      <td>0.616739</td>\n",
       "      <td>-1.586963</td>\n",
       "      <td>0.000041</td>\n",
       "      <td>...</td>\n",
       "      <td>0.036573</td>\n",
       "      <td>-0.182581</td>\n",
       "      <td>-0.226834</td>\n",
       "      <td>-1.029794</td>\n",
       "      <td>-0.118762</td>\n",
       "      <td>-0.228960</td>\n",
       "      <td>-0.024250</td>\n",
       "      <td>0.046547</td>\n",
       "      <td>-0.346230</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.178458</td>\n",
       "      <td>0.166055</td>\n",
       "      <td>-0.101567</td>\n",
       "      <td>0.369453</td>\n",
       "      <td>0.017198</td>\n",
       "      <td>-0.722891</td>\n",
       "      <td>0.396639</td>\n",
       "      <td>-0.187978</td>\n",
       "      <td>-0.483147</td>\n",
       "      <td>0.083094</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.323048</td>\n",
       "      <td>-1.083814</td>\n",
       "      <td>0.049838</td>\n",
       "      <td>-0.002872</td>\n",
       "      <td>0.295810</td>\n",
       "      <td>0.135883</td>\n",
       "      <td>-0.074191</td>\n",
       "      <td>0.004364</td>\n",
       "      <td>-0.150527</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.869017</td>\n",
       "      <td>-0.202287</td>\n",
       "      <td>-0.218739</td>\n",
       "      <td>1.496434</td>\n",
       "      <td>-0.403332</td>\n",
       "      <td>-0.013593</td>\n",
       "      <td>-0.342586</td>\n",
       "      <td>0.129402</td>\n",
       "      <td>0.911017</td>\n",
       "      <td>0.149568</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.458963</td>\n",
       "      <td>-1.058509</td>\n",
       "      <td>0.439679</td>\n",
       "      <td>-0.066668</td>\n",
       "      <td>-0.376792</td>\n",
       "      <td>-1.125226</td>\n",
       "      <td>0.053537</td>\n",
       "      <td>-0.039380</td>\n",
       "      <td>-0.305050</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.335053</td>\n",
       "      <td>0.331464</td>\n",
       "      <td>-2.057763</td>\n",
       "      <td>-0.346175</td>\n",
       "      <td>2.583234</td>\n",
       "      <td>2.854102</td>\n",
       "      <td>-0.187547</td>\n",
       "      <td>0.685154</td>\n",
       "      <td>-0.286614</td>\n",
       "      <td>-0.535903</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.191820</td>\n",
       "      <td>-0.650118</td>\n",
       "      <td>-0.114069</td>\n",
       "      <td>0.915936</td>\n",
       "      <td>0.730073</td>\n",
       "      <td>0.383879</td>\n",
       "      <td>-0.031902</td>\n",
       "      <td>0.029849</td>\n",
       "      <td>-0.347171</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.787763</td>\n",
       "      <td>-0.737892</td>\n",
       "      <td>-0.185794</td>\n",
       "      <td>0.362758</td>\n",
       "      <td>-0.550775</td>\n",
       "      <td>0.676564</td>\n",
       "      <td>-0.932369</td>\n",
       "      <td>0.390445</td>\n",
       "      <td>1.349983</td>\n",
       "      <td>-0.136095</td>\n",
       "      <td>...</td>\n",
       "      <td>0.331025</td>\n",
       "      <td>1.223539</td>\n",
       "      <td>0.264791</td>\n",
       "      <td>-0.541170</td>\n",
       "      <td>-0.571339</td>\n",
       "      <td>0.812785</td>\n",
       "      <td>0.017984</td>\n",
       "      <td>-0.054691</td>\n",
       "      <td>-0.232691</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-1.055540</td>\n",
       "      <td>0.942471</td>\n",
       "      <td>0.986697</td>\n",
       "      <td>1.560551</td>\n",
       "      <td>-0.138755</td>\n",
       "      <td>-0.253645</td>\n",
       "      <td>0.622974</td>\n",
       "      <td>-0.321826</td>\n",
       "      <td>-0.215914</td>\n",
       "      <td>0.816454</td>\n",
       "      <td>...</td>\n",
       "      <td>0.153985</td>\n",
       "      <td>0.985031</td>\n",
       "      <td>0.204281</td>\n",
       "      <td>0.455561</td>\n",
       "      <td>-0.456576</td>\n",
       "      <td>-0.244140</td>\n",
       "      <td>-0.833487</td>\n",
       "      <td>-0.419773</td>\n",
       "      <td>-0.173549</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0  1.836500 -0.545419 -0.462979  0.537174 -0.426143 -0.100606 -0.584764   \n",
       "1 -4.289880 -2.576061 -0.092256  1.976405  2.810033 -2.669128 -0.981883   \n",
       "2  1.131318  0.139818  0.586921  1.069291 -0.334908 -0.204938 -0.135526   \n",
       "3 -0.866956  1.373947  1.948343  2.686750 -0.366790  0.568632 -0.278349   \n",
       "4 -0.842670  1.401843  0.927235  1.070402  0.843883  0.467333  0.366716   \n",
       "5  1.178458  0.166055 -0.101567  0.369453  0.017198 -0.722891  0.396639   \n",
       "6  1.869017 -0.202287 -0.218739  1.496434 -0.403332 -0.013593 -0.342586   \n",
       "7  1.335053  0.331464 -2.057763 -0.346175  2.583234  2.854102 -0.187547   \n",
       "8  1.787763 -0.737892 -0.185794  0.362758 -0.550775  0.676564 -0.932369   \n",
       "9 -1.055540  0.942471  0.986697  1.560551 -0.138755 -0.253645  0.622974   \n",
       "\n",
       "         V8        V9       V10  ...         V21       V22       V23  \\\n",
       "0 -0.103956  2.268429 -0.365185  ...    0.085111  0.410736  0.137625   \n",
       "1 -0.470310 -0.025692  0.099528  ...   -0.473240 -0.307295 -2.789549   \n",
       "2  0.043821 -0.121117  0.182139  ...   -0.028126 -0.167062 -0.048054   \n",
       "3  0.739536 -1.655955  0.708396  ...    0.022719 -0.070619 -0.080307   \n",
       "4  0.616739 -1.586963  0.000041  ...    0.036573 -0.182581 -0.226834   \n",
       "5 -0.187978 -0.483147  0.083094  ...   -0.323048 -1.083814  0.049838   \n",
       "6  0.129402  0.911017  0.149568  ...   -0.458963 -1.058509  0.439679   \n",
       "7  0.685154 -0.286614 -0.535903  ...   -0.191820 -0.650118 -0.114069   \n",
       "8  0.390445  1.349983 -0.136095  ...    0.331025  1.223539  0.264791   \n",
       "9 -0.321826 -0.215914  0.816454  ...    0.153985  0.985031  0.204281   \n",
       "\n",
       "        V24       V25       V26       V27       V28    Amount  Class  \n",
       "0  0.602906 -0.350260  0.464407 -0.070917 -0.030486  0.049882      0  \n",
       "1  0.578976 -0.837979  0.372843  0.353451 -1.662202 -0.347171      0  \n",
       "2 -0.009912  0.417694 -0.479793  0.024360  0.023878 -0.208963      0  \n",
       "3  0.000816  0.092167  0.159131  0.157940 -0.014370 -0.253595      0  \n",
       "4 -1.029794 -0.118762 -0.228960 -0.024250  0.046547 -0.346230      0  \n",
       "5 -0.002872  0.295810  0.135883 -0.074191  0.004364 -0.150527      0  \n",
       "6 -0.066668 -0.376792 -1.125226  0.053537 -0.039380 -0.305050      0  \n",
       "7  0.915936  0.730073  0.383879 -0.031902  0.029849 -0.347171      0  \n",
       "8 -0.541170 -0.571339  0.812785  0.017984 -0.054691 -0.232691      0  \n",
       "9  0.455561 -0.456576 -0.244140 -0.833487 -0.419773 -0.173549      0  \n",
       "\n",
       "[10 rows x 30 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Looking at a sample of records\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    99508\n",
      "1      492\n",
      "Name: Class, dtype: int64\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#PLotting the frequencies of fraud and non-fraud transactions in the data\n",
    "count_classes = pd.value_counts(data['Class'], sort = True)\n",
    "print(count_classes)\n",
    "\n",
    "#Drawing a barplot\n",
    "count_classes.plot(kind = 'bar', rot=0)\n",
    "\n",
    "#Giving titles and labels to the plot\n",
    "plt.title(\"Transaction class distribution\")\n",
    "plt.xticks(range(2), LABELS)\n",
    "plt.xlabel(\"Class\")\n",
    "plt.ylabel(\"Frequency\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "#Converting data to array\n",
    "data = np.array(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(80000, 30)\n",
      "(20000, 30)\n"
     ]
    }
   ],
   "source": [
    "#Splitting the data into train and test and observing their dimensions\n",
    "X_train, X_test = train_test_split(data, test_size=0.2, random_state=RANDOM_SEED)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0., 1.]), array([79591,   409], dtype=int64))\n",
      "(array([0., 1.]), array([19917,    83], dtype=int64))\n"
     ]
    }
   ],
   "source": [
    "#Obtaining the fraud and non-fraud records in train\n",
    "print(np.unique(X_train[:,29],return_counts=True))\n",
    "print(np.unique(X_test[:,29],return_counts=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(79591, 29)\n"
     ]
    }
   ],
   "source": [
    "#Now consider only the non-fraud records for training\n",
    "X_train_NF = X_train[X_train[:,-1] == 0]\n",
    "X_train_NF = X_train_NF[:,:-1]\n",
    "print(X_train_NF.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(409, 30)\n"
     ]
    }
   ],
   "source": [
    "#Separating out the fraud records from the train \n",
    "X_train_F = X_train[X_train[:,-1] == 1]\n",
    "print(X_train_F.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20409, 30)\n"
     ]
    }
   ],
   "source": [
    "#Adding/concatenating the fraud records from train data to the test\n",
    "X_test=np.concatenate((X_test,X_train_F),axis=0)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test,X_eval = train_test_split(X_test, test_size=0.2, random_state=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16327, 30)\n",
      "(4082, 30)\n"
     ]
    }
   ],
   "source": [
    "print(X_test.shape)\n",
    "print(X_eval.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Separating the independent and the class variable\n",
    "y_test = X_test[:,-1]\n",
    "X_test = X_test[:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16327, 1)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Expanding the dimensions of y for later concatenation\n",
    "y_test = np.expand_dims(y_test, axis=1)\n",
    "y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(79591, 29)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_NF.shape)\n",
    "input_dim = X_train_NF.shape[1]\n",
    "encoding_dim = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder = Sequential()\n",
    "\n",
    "autoencoder.add(Dropout(0.2, input_shape=(input_dim,)))\n",
    "autoencoder.add(Dense(encoding_dim, activation='relu'))\n",
    "autoencoder.add(Dense(input_dim, activation='linear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_epoch = 100\n",
    "batch_size = 32\n",
    "\n",
    "autoencoder.compile(optimizer='adam', \n",
    "                    loss='mean_squared_error', \n",
    "                    metrics=['mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 55713 samples, validate on 23878 samples\n",
      "Epoch 1/1\n",
      "55713/55713 [==============================] - 27s 478us/step - loss: 0.6801 - mean_squared_error: 0.6801 - val_loss: 0.3655 - val_mean_squared_error: 0.3655\n",
      "Train on 55713 samples, validate on 23878 samples\n",
      "Epoch 1/1\n",
      "55713/55713 [==============================] - 22s 403us/step - loss: 0.4060 - mean_squared_error: 0.4060 - val_loss: 0.2559 - val_mean_squared_error: 0.2559\n",
      "Train on 55713 samples, validate on 23878 samples\n",
      "Epoch 1/1\n",
      "55713/55713 [==============================] - 26s 471us/step - loss: 0.3674 - mean_squared_error: 0.3674 - val_loss: 0.2344 - val_mean_squared_error: 0.2344A: 25s - loss: 0.3436 - mean_square - ETA: 30s - loss: 0.3390 - mean_squared_error: 0.3 - ETA: 28s - loss: 0.3390 - mean_squared_error:  - ETA: 27s - loss: 0.3376 - mean_squar - ETA: 24s - loss: 0.3394 - mean_square - ETA: 22s  - ETA: 3s - loss: 0.3674 \n",
      "Train on 55713 samples, validate on 23878 samples\n",
      "Epoch 1/1\n",
      "55713/55713 [==============================] - 31s 551us/step - loss: 0.3562 - mean_squared_error: 0.3562 - val_loss: 0.2314 - val_mean_squared_error: 0.2314\n",
      "Train on 55713 samples, validate on 23878 samples\n",
      "Epoch 1/1\n",
      "55713/55713 [==============================] - 135s 2ms/step - loss: 0.3549 - mean_squared_error: 0.3549 - val_loss: 0.2284 - val_mean_squared_error: 0.2284\n",
      "Train on 55713 samples, validate on 23878 samples\n",
      "Epoch 1/1\n",
      "55713/55713 [==============================] - 27s 489us/step - loss: 0.3511 - mean_squared_error: 0.3511 - val_loss: 0.2280 - val_mean_squared_error: 0.2280\n",
      "Train on 55713 samples, validate on 23878 samples\n",
      "Epoch 1/1\n",
      "55713/55713 [==============================] - 26s 469us/step - loss: 0.3461 - mean_squared_error: 0.3461 - val_loss: 0.2260 - val_mean_squared_error: 0.2260\n",
      "Train on 55713 samples, validate on 23878 samples\n",
      "Epoch 1/1\n",
      "55713/55713 [==============================] - 26s 461us/step - loss: 0.3452 - mean_squared_error: 0.3452 - val_loss: 0.2260 - val_mean_squared_error: 0.2260\n",
      "Train on 55713 samples, validate on 23878 samples\n",
      "Epoch 1/1\n",
      "55713/55713 [==============================] - 26s 459us/step - loss: 0.3452 - mean_squared_error: 0.3452 - val_loss: 0.2258 - val_mean_squared_error: 0.2258\n",
      "Train on 55713 samples, validate on 23878 samples\n",
      "Epoch 1/1\n",
      "55713/55713 [==============================] - 25s 455us/step - loss: 0.3475 - mean_squared_error: 0.3475 - val_loss: 0.2272 - val_mean_squared_error: 0.2272\n",
      "Train on 55713 samples, validate on 23878 samples\n",
      "Epoch 1/1\n",
      "55713/55713 [==============================] - 25s 453us/step - loss: 0.3433 - mean_squared_error: 0.3433 - val_loss: 0.2257 - val_mean_squared_error: 0.2257\n",
      "Train on 55713 samples, validate on 23878 samples\n",
      "Epoch 1/1\n",
      "55713/55713 [==============================] - 27s 476us/step - loss: 0.3425 - mean_squared_error: 0.3425 - val_loss: 0.2278 - val_mean_squared_error: 0.2278\n",
      "Train on 55713 samples, validate on 23878 samples\n",
      "Epoch 1/1\n",
      "55713/55713 [==============================] - 27s 478us/step - loss: 0.3392 - mean_squared_error: 0.3392 - val_loss: 0.2260 - val_mean_squared_error: 0.2260red_ - ET\n",
      "Train on 55713 samples, validate on 23878 samples\n",
      "Epoch 1/1\n",
      "55713/55713 [==============================] - 27s 481us/step - loss: 0.3387 - mean_squared_error: 0.3387 - val_loss: 0.2298 - val_mean_squared_error: 0.2298\n",
      "Train on 55713 samples, validate on 23878 samples\n",
      "Epoch 1/1\n",
      "55713/55713 [==============================] - 25s 449us/step - loss: 0.3355 - mean_squared_error: 0.3355 - val_loss: 0.2286 - val_mean_squared_error: 0.2286\n",
      "Train on 55713 samples, validate on 23878 samples\n",
      "Epoch 1/1\n",
      "55713/55713 [==============================] - 25s 445us/step - loss: 0.3349 - mean_squared_error: 0.3349 - val_loss: 0.2242 - val_mean_squared_error: 0.2242\n",
      "Train on 55713 samples, validate on 23878 samples\n",
      "Epoch 1/1\n",
      "55713/55713 [==============================] - 24s 433us/step - loss: 0.3363 - mean_squared_error: 0.3363 - val_loss: 0.2229 - val_mean_squared_error: 0.2229\n",
      "Train on 55713 samples, validate on 23878 samples\n",
      "Epoch 1/1\n",
      "55713/55713 [==============================] - 26s 465us/step - loss: 0.3329 - mean_squared_error: 0.3329 - val_loss: 0.2243 - val_mean_squared_error: 0.2243\n",
      "Train on 55713 samples, validate on 23878 samples\n",
      "Epoch 1/1\n",
      "55713/55713 [==============================] - 24s 433us/step - loss: 0.3375 - mean_squared_error: 0.3375 - val_loss: 0.2243 - val_mean_squared_error: 0.2243\n",
      "Train on 55713 samples, validate on 23878 samples\n",
      "Epoch 1/1\n",
      "55713/55713 [==============================] - 25s 447us/step - loss: 0.3341 - mean_squared_error: 0.3341 - val_loss: 0.2263 - val_mean_squared_error: 0.2263\n",
      "Train on 55713 samples, validate on 23878 samples\n",
      "Epoch 1/1\n",
      "55713/55713 [==============================] - 24s 428us/step - loss: 0.3352 - mean_squared_error: 0.3352 - val_loss: 0.2339 - val_mean_squared_error: 0.2339\n",
      "Train on 55713 samples, validate on 23878 samples\n",
      "Epoch 1/1\n",
      "55713/55713 [==============================] - 30s 536us/step - loss: 0.3329 - mean_squared_error: 0.3329 - val_loss: 0.2251 - val_mean_squared_error: 0.2251\n",
      "Train on 55713 samples, validate on 23878 samples\n",
      "Epoch 1/1\n",
      "55713/55713 [==============================] - 37s 667us/step - loss: 0.3362 - mean_squared_error: 0.3362 - val_loss: 0.2249 - val_mean_squared_error: 0.2249\n",
      "Train on 55713 samples, validate on 23878 samples\n",
      "Epoch 1/1\n",
      "55713/55713 [==============================] - 25s 452us/step - loss: 0.3309 - mean_squared_error: 0.3309 - val_loss: 0.2229 - val_mean_squared_error: 0.2229\n",
      "Train on 55713 samples, validate on 23878 samples\n",
      "Epoch 1/1\n",
      "55713/55713 [==============================] - 23s 413us/step - loss: 0.3354 - mean_squared_error: 0.3354 - val_loss: 0.2232 - val_mean_squared_error: 0.2232\n",
      "Train on 55713 samples, validate on 23878 samples\n",
      "Epoch 1/1\n",
      "55713/55713 [==============================] - 25s 447us/step - loss: 0.3314 - mean_squared_error: 0.3314 - val_loss: 0.2264 - val_mean_squared_error: 0.2264\n",
      "Train on 55713 samples, validate on 23878 samples\n",
      "Epoch 1/1\n",
      "55713/55713 [==============================] - 25s 446us/step - loss: 0.3305 - mean_squared_error: 0.3305 - val_loss: 0.2245 - val_mean_squared_error: 0.2245\n",
      "Train on 55713 samples, validate on 23878 samples\n",
      "Epoch 1/1\n",
      "55713/55713 [==============================] - 24s 426us/step - loss: 0.3312 - mean_squared_error: 0.3312 - val_loss: 0.2240 - val_mean_squared_error: 0.2240\n",
      "Train on 55713 samples, validate on 23878 samples\n",
      "Epoch 1/1\n",
      "55713/55713 [==============================] - 26s 459us/step - loss: 0.3336 - mean_squared_error: 0.3336 - val_loss: 0.2254 - val_mean_squared_error: 0.2254\n",
      "Train on 55713 samples, validate on 23878 samples\n",
      "Epoch 1/1\n",
      "55713/55713 [==============================] - 28s 508us/step - loss: 0.3332 - mean_squared_error: 0.3332 - val_loss: 0.2243 - val_mean_squared_error: 0.2243\n",
      "Train on 55713 samples, validate on 23878 samples\n",
      "Epoch 1/1\n",
      "55713/55713 [==============================] - 135s 2ms/step - loss: 0.3316 - mean_squared_error: 0.3316 - val_loss: 0.2235 - val_mean_squared_error: 0.2235oss: 0.3322 - mea\n",
      "Train on 55713 samples, validate on 23878 samples\n",
      "Epoch 1/1\n",
      "55713/55713 [==============================] - 26s 465us/step - loss: 0.3317 - mean_squared_error: 0.3317 - val_loss: 0.2259 - val_mean_squared_error: 0.2259\n",
      "Train on 55713 samples, validate on 23878 samples\n",
      "Epoch 1/1\n",
      "55713/55713 [==============================] - 25s 456us/step - loss: 0.3311 - mean_squared_error: 0.3311 - val_loss: 0.2252 - val_mean_squared_error: 0.2252\n",
      "Train on 55713 samples, validate on 23878 samples\n",
      "Epoch 1/1\n",
      "55713/55713 [==============================] - 23s 417us/step - loss: 0.3338 - mean_squared_error: 0.3338 - val_loss: 0.2239 - val_mean_squared_error: 0.2239\n",
      "Train on 55713 samples, validate on 23878 samples\n",
      "Epoch 1/1\n",
      "55713/55713 [==============================] - 24s 432us/step - loss: 0.3322 - mean_squared_error: 0.3322 - val_loss: 0.2257 - val_mean_squared_error: 0.2257\n",
      "Train on 55713 samples, validate on 23878 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55713/55713 [==============================] - 24s 439us/step - loss: 0.3346 - mean_squared_error: 0.3346 - val_loss: 0.2245 - val_mean_squared_error: 0.2245loss: 0.3427 - mean_squar - ETA: 6s - loss: 0 - ETA: 0s - loss: 0.3344 - \n",
      "Train on 55713 samples, validate on 23878 samples\n",
      "Epoch 1/1\n",
      "55713/55713 [==============================] - 23s 411us/step - loss: 0.3305 - mean_squared_error: 0.3305 - val_loss: 0.2236 - val_mean_squared_error: 0.2236\n",
      "Train on 55713 samples, validate on 23878 samples\n",
      "Epoch 1/1\n",
      "55713/55713 [==============================] - 24s 426us/step - loss: 0.3302 - mean_squared_error: 0.3302 - val_loss: 0.2252 - val_mean_squared_error: 0.2252\n",
      "Train on 55713 samples, validate on 23878 samples\n",
      "Epoch 1/1\n",
      "55713/55713 [==============================] - 25s 442us/step - loss: 0.3305 - mean_squared_error: 0.3305 - val_loss: 0.2241 - val_mean_squared_error: 0.2241\n",
      "Train on 55713 samples, validate on 23878 samples\n",
      "Epoch 1/1\n",
      "55713/55713 [==============================] - 23s 412us/step - loss: 0.3308 - mean_squared_error: 0.3308 - val_loss: 0.2246 - val_mean_squared_error: 0.2246\n",
      "Train on 55713 samples, validate on 23878 samples\n",
      "Epoch 1/1\n",
      "55713/55713 [==============================] - 29s 518us/step - loss: 0.3279 - mean_squared_error: 0.3279 - val_loss: 0.2258 - val_mean_squared_error: 0.2258ss: 0.3236 - mean_s - ETA: 3s - ETA: 2s - loss: 0.3279 - mean_squ - ETA: 1s - - ETA: 0s - loss: 0.3286 \n",
      "Train on 55713 samples, validate on 23878 samples\n",
      "Epoch 1/1\n",
      "55713/55713 [==============================] - 133s 2ms/step - loss: 0.3314 - mean_squared_error: 0.3314 - val_loss: 0.2242 - val_mean_squared_error: 0.2242\n",
      "Train on 55713 samples, validate on 23878 samples\n",
      "Epoch 1/1\n",
      "55713/55713 [==============================] - 41s 732us/step - loss: 0.3317 - mean_squared_error: 0.3317 - val_loss: 0.2229 - val_mean_squared_error: 0.2229\n",
      "Train on 55713 samples, validate on 23878 samples\n",
      "Epoch 1/1\n",
      "55713/55713 [==============================] - 43s 778us/step - loss: 0.3293 - mean_squared_error: 0.3293 - val_loss: 0.2226 - val_mean_squared_error: 0.2226s\n",
      "Train on 55713 samples, validate on 23878 samples\n",
      "Epoch 1/1\n",
      "55713/55713 [==============================] - 23s 419us/step - loss: 0.3324 - mean_squared_error: 0.3324 - val_loss: 0.2272 - val_mean_squared_error: 0.2272\n",
      "Train on 55713 samples, validate on 23878 samples\n",
      "Epoch 1/1\n",
      "55713/55713 [==============================] - 23s 409us/step - loss: 0.3301 - mean_squared_error: 0.3301 - val_loss: 0.2230 - val_mean_squared_error: 0.2230\n",
      "Train on 55713 samples, validate on 23878 samples\n",
      "Epoch 1/1\n",
      "55713/55713 [==============================] - 23s 410us/step - loss: 0.3282 - mean_squared_error: 0.3282 - val_loss: 0.2296 - val_mean_squared_error: 0.2296\n",
      "Train on 55713 samples, validate on 23878 samples\n",
      "Epoch 1/1\n",
      "55713/55713 [==============================] - 25s 451us/step - loss: 0.3310 - mean_squared_error: 0.3310 - val_loss: 0.2251 - val_mean_squared_error: 0.2251\n",
      "Train on 55713 samples, validate on 23878 samples\n",
      "Epoch 1/1\n",
      "55713/55713 [==============================] - 26s 464us/step - loss: 0.3292 - mean_squared_error: 0.3292 - val_loss: 0.2290 - val_mean_squared_error: 0.2290\n",
      "Train on 55713 samples, validate on 23878 samples\n",
      "Epoch 1/1\n",
      "55713/55713 [==============================] - 22s 393us/step - loss: 0.3298 - mean_squared_error: 0.3298 - val_loss: 0.2257 - val_mean_squared_error: 0.2257\n",
      "Train on 55713 samples, validate on 23878 samples\n",
      "Epoch 1/1\n",
      "55713/55713 [==============================] - 19s 334us/step - loss: 0.3317 - mean_squared_error: 0.3317 - val_loss: 0.2252 - val_mean_squared_error: 0.2252\n",
      "Train on 55713 samples, validate on 23878 samples\n",
      "Epoch 1/1\n",
      "55713/55713 [==============================] - 22s 397us/step - loss: 0.3269 - mean_squared_error: 0.3269 - val_loss: 0.2278 - val_mean_squared_error: 0.2278\n",
      "Train on 55713 samples, validate on 23878 samples\n",
      "Epoch 1/1\n",
      "55713/55713 [==============================] - 123s 2ms/step - loss: 0.3269 - mean_squared_error: 0.3269 - val_loss: 0.2250 - val_mean_squared_error: 0.2250\n",
      "Train on 55713 samples, validate on 23878 samples\n",
      "Epoch 1/1\n",
      "34080/55713 [=================>............] - ETA: 7s - loss: 0.3266 - mean_squared_error: 0.3266 - ETA: 15s - loss: 0.31"
     ]
    }
   ],
   "source": [
    "hist = []\n",
    "for _ in range(100):\n",
    "    hist.append(autoencoder.fit(X_train_NF, X_train_NF,\n",
    "                    epochs=1,\n",
    "                    batch_size=batch_size,\n",
    "                    shuffle=True,\n",
    "                     validation_split=0.3,\n",
    "                    verbose=1).history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'val_loss': [0.33405528783259036],\n",
       "  'val_mean_squared_error': [0.33405528783259036],\n",
       "  'loss': [0.6574461971794147],\n",
       "  'mean_squared_error': [0.6574461971794147]},\n",
       " {'val_loss': [0.2524798494685744],\n",
       "  'val_mean_squared_error': [0.2524798494685744],\n",
       "  'loss': [0.39722355654259534],\n",
       "  'mean_squared_error': [0.39722355654259534]},\n",
       " {'val_loss': [0.23742848752041998],\n",
       "  'val_mean_squared_error': [0.23742848752041998],\n",
       "  'loss': [0.3614965733514152],\n",
       "  'mean_squared_error': [0.3614965733514152]},\n",
       " {'val_loss': [0.23097310399018656],\n",
       "  'val_mean_squared_error': [0.23097310399018656],\n",
       "  'loss': [0.35076765617275096],\n",
       "  'mean_squared_error': [0.35076765617275096]},\n",
       " {'val_loss': [0.23219408737970604],\n",
       "  'val_mean_squared_error': [0.23219408737970604],\n",
       "  'loss': [0.34823538132079157],\n",
       "  'mean_squared_error': [0.34823538132079157]}]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hist[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.6033593 ,  0.94757324,  1.7551892 ,  0.8572338 , -0.8328218 ,\n",
       "         0.5189227 , -0.5616846 ,  1.1336945 ,  0.4842893 , -0.8036911 ,\n",
       "        -1.416091  ,  0.28365517, -0.92414784, -0.14528751, -1.8320006 ,\n",
       "        -0.4907556 ,  0.530109  ,  0.00432374,  0.2000157 , -0.05800389,\n",
       "         0.00736931,  0.07622877, -0.0389892 , -0.06887589, -0.03673813,\n",
       "        -0.00719737,  0.00309072,  0.09111511, -0.23702683],\n",
       "       [ 1.2884982 , -0.31085998,  0.12979531, -0.4310326 , -0.71386033,\n",
       "        -1.4945496 , -0.05842292, -0.3626615 , -0.9554357 ,  0.61991006,\n",
       "         0.3646551 , -0.22123933,  0.4042024 , -0.03933859,  0.11359358,\n",
       "         0.04138162,  0.13468468, -0.01329425,  0.05333993, -0.09490938,\n",
       "        -0.01446912,  0.00730772, -0.0052765 , -0.0423546 , -0.03087896,\n",
       "        -0.08038861,  0.00960309,  0.00466691, -0.18897496]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Making predictions on the train data\n",
    "predictions=autoencoder.predict(X_train_NF)\n",
    "\n",
    "predictions[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16327, 30)\n",
      "(15942, 30)\n",
      "(385, 30)\n"
     ]
    }
   ],
   "source": [
    "##We want to separate out fraud records and non-fraud records for later use\n",
    "f = np.hstack((X_test,y_test))\n",
    "print(f.shape)\n",
    "\n",
    "test_nf=f[f[:,29]==0]\n",
    "print(test_nf.shape)\n",
    "\n",
    "test_f=f[f[:,29]==1]\n",
    "print(test_f.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15942/15942 [==============================] - 3s 202us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.23103991510626243, 0.23103991510626243]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Getting the errors from the non fraud data separately \n",
    "autoencoder.evaluate(test_nf[:,:29],test_nf[:,:29])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "385/385 [==============================] - 0s 223us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[18.897587015721705, 18.897587015721705]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Getting the errors from the fraud data separately\n",
    "autoencoder.evaluate(test_f[:,:29],test_f[:,:29])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Obtaining predictions for non fraud records\n",
    "predictions_nf=autoencoder.predict(test_nf[:,:29])\n",
    "\n",
    "#Obtaining predictions for fraud records\n",
    "predictions_f=autoencoder.predict(test_f[:,:29])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.23103991513673885"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Identifying the error computation method by autoencoder(Mean Squared Error). The computation is as follows \n",
    "np.mean(np.square(np.abs(test_nf[:,:29]-predictions_nf)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.36082535, 0.0558622 , 0.19217769, 0.06870034, 0.33538298])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Computing errors on the non-fraud data\n",
    "errors_nf = np.mean(np.square(np.abs(test_nf[:,:29]-predictions_nf)), axis=1)\n",
    "errors_nf[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([82.0411392 , 68.56533548, 17.21567645,  3.9810928 , 66.0933357 ])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Computing errors on the fraud data\n",
    "errors_f = np.mean(np.square(np.abs(test_f[:,:29]-predictions_f)), axis=1)\n",
    "errors_f[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.015557321633021773\n",
      "130.01498376192282\n",
      "0.12250105083994323\n",
      "0.036041630581479966\n",
      "129.80487354807744\n",
      "7.8113445156713945\n"
     ]
    }
   ],
   "source": [
    "#Computing the distribution of errors in both non-fraud and fraud data\n",
    "print(np.min(errors_nf))\n",
    "print(np.max(errors_nf))\n",
    "print(np.median(errors_nf))\n",
    "\n",
    "print(np.min(errors_f))\n",
    "print(np.max(errors_f))\n",
    "print(np.median(errors_f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'whiskers': [<matplotlib.lines.Line2D at 0x237c97857b8>,\n",
       "  <matplotlib.lines.Line2D at 0x237c9785cf8>],\n",
       " 'caps': [<matplotlib.lines.Line2D at 0x237c978e198>,\n",
       "  <matplotlib.lines.Line2D at 0x237c978e5f8>],\n",
       " 'boxes': [<matplotlib.lines.Line2D at 0x237c9785668>],\n",
       " 'medians': [<matplotlib.lines.Line2D at 0x237c978ea58>],\n",
       " 'fliers': [<matplotlib.lines.Line2D at 0x237c978eeb8>],\n",
       " 'means': []}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#PLotting the error box plots \n",
    "\n",
    "plt.subplot(1, 2,1)\n",
    "plt.boxplot(errors_f)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.boxplot(errors_nf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n",
      "192\n",
      "10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "7971"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Experimentation to fix a threshold for classification of a transaction into fraud or non-fraud\n",
    "print(sum(errors_nf>np.median(errors_f)))\n",
    "print(sum(errors_f<np.median(errors_f)))\n",
    "print(sum(errors_f<np.median(errors_nf)))\n",
    "sum(errors_nf>np.median(errors_nf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15942,)\n",
      "(385,)\n"
     ]
    }
   ],
   "source": [
    "print(errors_nf.shape)\n",
    "print(errors_f.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15942, 29)\n",
      "(385, 29)\n"
     ]
    }
   ],
   "source": [
    "print(predictions_nf.shape)\n",
    "print(predictions_f.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.36082535 0.0558622  0.19217769 ... 0.13356274 0.09450706 0.05071564]\n",
      "0.22520954219491793\n"
     ]
    }
   ],
   "source": [
    "test_pred = autoencoder.predict(X_test[:,:29])\n",
    "test_recon  = (((test_pred-X_test)**2).mean(-1))\n",
    "print(test_recon)\n",
    "\n",
    "train_pred = autoencoder.predict(X_train_NF[:,:29])\n",
    "mean_recon = (((train_pred - X_train_NF)**2).mean(-1).mean())\n",
    "print(mean_recon)\n",
    "\n",
    "from sklearn.metrics import precision_score,recall_score,f1_score,confusion_matrix\n",
    "\n",
    "scores_f1 = []\n",
    "thres = []\n",
    "\n",
    "th = 0\n",
    "for i in range(100):\n",
    "    th+=0.1\n",
    "    fraud = (test_recon>mean_recon+th)\n",
    "    scores_f1.append(f1_score(y_test,fraud))\n",
    "    thres.append(th+mean_recon)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16327, 29)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.925209542194919\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[15876,    66],\n",
       "       [   90,   295]], dtype=int64)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(thres, scores_f1)\n",
    "\n",
    "print(thres[np.array(scores_f1).argmax()])\n",
    "\n",
    "fraud = (test_recon>thres[np.array(scores_f1).argmax()])\n",
    "\n",
    "confusion_matrix(y_test, fraud)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Predicting on Valdation \n",
    "\n",
    "predictions_eval=autoencoder.predict(X_eval[:,:29])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors_eval=np.square(np.subtract(predictions_eval,X_eval[:,:29]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "fraud_eval=(((errors_eval-X_eval[:,:29])**2).mean(-1))>2.925209542194919"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3680  295]\n",
      " [  14   93]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_true=X_eval[:,29],y_pred=fraud_eval))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
